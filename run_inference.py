import cv2
import numpy as np
import tensorflow as tf
import os
from tensorflow.keras.preprocessing import image

# âœ… æ¨¡å‹å’Œæ ‡ç­¾è·¯å¾„
MODEL_PATH = 'checkpoints/epoch_03_val_acc_0.84.h5'
LABELS_PATH = 'data/asl_alphabet/asl_alphabet_train/asl_alphabet_train'

# âœ… åŠ è½½æ¨¡å‹å’Œæ ‡ç­¾
model = tf.keras.models.load_model(MODEL_PATH)
class_names = sorted(os.listdir(LABELS_PATH))

# âœ… æ‰“å¼€æ‘„åƒå¤´
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
    exit()

print("âœ… æ‘„åƒå¤´å·²å¼€å¯ï¼ŒæŒ‰ Q é€€å‡ºç¨‹åº")

while True:
    ret, frame = cap.read()
    if not ret:
        print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
        break

    # ğŸ“Œ å®šä¹‰ ROIï¼ˆä¸­é—´çš„æ­£æ–¹å½¢åŒºåŸŸï¼‰
    h, w, _ = frame.shape
    roi_size = 300
    x1 = w // 2 - roi_size // 2
    y1 = h // 2 - roi_size // 2
    x2 = x1 + roi_size
    y2 = y1 + roi_size
    roi = frame[y1:y2, x1:x2]

    # âœ… å›¾åƒå¤„ç†
    img = cv2.resize(roi, (224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = img_array / 255.0

    # âœ… æ¨¡å‹é¢„æµ‹
    prediction = model.predict(img_array)[0]
    predicted_index = np.argmax(prediction)
    predicted_label = class_names[predicted_index]
    confidence = prediction[predicted_index]

    # âœ… æ˜¾ç¤ºç»“æœ
    label_text = f"{predicted_label} ({confidence:.2f})"
    cv2.putText(frame, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (10, 255, 10), 2)
    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)

    cv2.imshow("Sign Language Recognition", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()